{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/content/working/combined_files\"\n",
    "\n",
    "# Clear the contents of the output directory\n",
    "shutil.rmtree(output_dir, ignore_errors=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Contents of {output_dir} cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = \"/content/drive/MyDrive/16000_pcm_speeches\"\n",
    "\n",
    "# Output directory to save the combined files\n",
    "output_dir = \"/content/working/combined_files\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of speaker folders\n",
    "speaker_folders = [\n",
    "    \"Benjamin_Netanyau\",\n",
    "    \"Jens_Stoltenberg\",\n",
    "    \"Julia_Gillard\",\n",
    "    \"Magaret_Tarcher\",\n",
    "    \"Nelson_Mandela\"\n",
    "]\n",
    "\n",
    "# Number of files to combine for each speaker\n",
    "num_files_to_combine = 120\n",
    "\n",
    "# Iterate over each speaker's folder\n",
    "for speaker_folder in speaker_folders:\n",
    "    speaker_folder_path = os.path.join(dataset_path, speaker_folder)\n",
    "\n",
    "    # List the first num_files_to_combine WAV files in the speaker's folder\n",
    "    wav_files = [f\"{i}.wav\" for i in range(num_files_to_combine)]\n",
    "\n",
    "    # Combine all WAV files into a single long file\n",
    "    combined_audio = []\n",
    "    for wav_file in wav_files:\n",
    "        wav_file_path = os.path.join(speaker_folder_path, wav_file)\n",
    "        audio, sr = librosa.load(wav_file_path, sr=None)\n",
    "        combined_audio.extend(audio)\n",
    "\n",
    "    # Save the combined audio file\n",
    "    output_file_path = os.path.join(output_dir, f\"{speaker_folder}_combined.wav\")\n",
    "    sf.write(output_file_path, combined_audio, sr)\n",
    "\n",
    "print(\"Combination complete. Combined files saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "\n",
    "# Function to play audio file\n",
    "def play_audio(audio_path):\n",
    "    display(Audio(filename=audio_path))\n",
    "\n",
    "# Play a specific combined audio file\n",
    "speaker_folder = \"Benjamin_Netanyau_combined\"\n",
    "audio_path = os.path.join(output_dir, f\"{speaker_folder}.wav\")\n",
    "print(f\"Click the play button to listen: {audio_path}\")\n",
    "play_audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to play audio file\n",
    "def play_audio(audio_path):\n",
    "    display(Audio(filename=audio_path))\n",
    "\n",
    "# Play a specific combined audio file\n",
    "speaker_folder = \"Nelson_Mandela_combined\"\n",
    "audio_path = os.path.join(output_dir, f\"{speaker_folder}.wav\")\n",
    "print(f\"Click the play button to listen: {audio_path}\")\n",
    "play_audio(audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "# Function to plot the waveform, spectrogram, and MFCCs\n",
    "def plot_audio_features(audio_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Extract speaker name from the file path\n",
    "    speaker_name = os.path.basename(audio_path).split('_')[0]\n",
    "\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title(f'Waveform - {speaker_name}')\n",
    "\n",
    "    # Plot the spectrogram\n",
    "    plt.subplot(3, 1, 2)\n",
    "    D = librosa.amplitude_to_db(librosa.stft(y), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Spectrogram - {speaker_name}')\n",
    "\n",
    "    # Plot the MFCCs\n",
    "    plt.subplot(3, 1, 3)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'MFCCs - {speaker_name}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Paths to the combined audio files\n",
    "audio_paths = [\n",
    "    '/content/working/combined_files/Benjamin_Netanyau_combined.wav',\n",
    "    '/content/working/combined_files/Nelson_Mandela_combined.wav'\n",
    "]\n",
    "\n",
    "# Plot features for each audio file\n",
    "for audio_path in audio_paths:\n",
    "    plot_audio_features(audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set the parent directory for speaker folders\n",
    "parent_dir = \"/content/drive/MyDrive/16000_pcm_speeches\"\n",
    "\n",
    "# List of speaker folders\n",
    "speaker_folders = [\n",
    "    \"Benjamin_Netanyau\",\n",
    "    \"Jens_Stoltenberg\",\n",
    "    \"Julia_Gillard\",\n",
    "    \"Magaret_Tarcher\",\n",
    "    \"Nelson_Mandela\"\n",
    "]\n",
    "\n",
    "def extract_features(parent_dir, speaker_folders):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i, speaker_folder in enumerate(speaker_folders):\n",
    "        speaker_folder_path = os.path.join(parent_dir, speaker_folder)\n",
    "\n",
    "        for filename in os.listdir(speaker_folder_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(speaker_folder_path, filename)\n",
    "                audio, sr = librosa.load(file_path, sr=None, duration=1)\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "                # Normalize MFCC features\n",
    "                mfccs = StandardScaler().fit_transform(mfccs)\n",
    "\n",
    "                features.append(mfccs.T)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract features and labels\n",
    "X, y = extract_features(parent_dir, speaker_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in X[:1]:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels with explicit classes\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "label_encoder.classes_ = np.array(speaker_folders)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of training and validation data\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Validation Data Shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(speaker_folders), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Check if EarlyStopping triggered\n",
    "if early_stopping.stopped_epoch > 0:\n",
    "    print(\"Early stopping triggered at epoch\", early_stopping.stopped_epoch + 1)\n",
    "else:\n",
    "    print(\"Training completed without early stopping\")\n",
    "\n",
    "# Plot training vs validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_probabilities = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Decode labels back to original format\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_decoded, y_pred_decoded, labels=speaker_folders)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_decoded, y_pred_decoded)\n",
    "print(f\"Test Evaluation Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test_decoded, y_pred_decoded, labels=speaker_folders, average='weighted')\n",
    "print(f\"Weighted F1 Score: {f1}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=speaker_folders, yticklabels=speaker_folders)\n",
    "\n",
    "# Rotate x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
